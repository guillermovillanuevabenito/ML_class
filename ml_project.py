# -*- coding: utf-8 -*-
"""ML_project.ipynb

Automatically generated by Colaboratory

Original file is located at
    https://colab.research.google.com/drive/1dmkIsHgbeDnUQLN1JI3XuRhG7BOeQjmZ
"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import numpy as np
import pandas as pd
import matplotlib as plt
from google.colab import drive
from datetime import datetime
from sklearn.model_selection import train_test_split
from sklearn import svm
from sklearn.ensemble import RandomForestRegressor

drive.mount('/content/drive')

"""## Preprocess data"""

# Import data from google drive
df = pd.read_csv('/content/drive/MyDrive/US_Accidents_Dec21_updated.csv')
df.head()

# Select explanatory random variables
df_filtered = df.loc[:,['Severity','Start_Time','Start_Lat','Start_Lng','Temperature(F)','Wind_Speed(mph)','Humidity(%)','Visibility(mi)','Precipitation(in)']]

# Drop rows with NaN values
df_filtered = df_filtered.dropna()
df_filtered = df_filtered.reset_index(drop=True)

# Compute histogram of classes in the filtered data set
df_class = df_filtered.Severity

import matplotlib.pyplot as plt

plt.hist(df_class, bins=np.arange(5)+0.5)
ticks = [1,2,3,4]
labels = ["Class 1", "Class 2", "Class 3", "Class 4"]
plt.xticks(ticks, labels,fontsize=10)
plt.show()

# Function that create both training and test sets with equally represented classes
def create_training_test_set(df):
  df_1 = df_filtered[df_filtered.Severity == 1]
  df_1 = df_1.reset_index(drop=True)
  df1_s = df_1.sample(n=5000)
  df1_s = df1_s.reset_index(drop=True)

  df_2 = df_filtered[df_filtered.Severity == 2]
  df_2 = df_2.reset_index(drop=True)
  df2_s = df_2.sample(n=5000)
  df2_s = df2_s.reset_index(drop=True)

  df_3 = df_filtered[df_filtered.Severity == 3]
  df_3 = df_3.reset_index(drop=True)
  df3_s = df_3.sample(n=5000)
  df3_s = df3_s.reset_index(drop=True)

  df_4 = df_filtered[df_filtered.Severity == 4]
  df_4 = df_4.reset_index(drop=True)
  df4_s = df_4.sample(n=5000)
  df4_s = df4_s.reset_index(drop=True)

  frames = [df1_s, df2_s, df3_s, df4_s]
  result = pd.concat(frames)
  result = result.reset_index(drop=True)

  df_train, df_test = train_test_split(result, test_size=0.2)
  df_train = df_train.reset_index(drop=True)
  df_test = df_test.reset_index(drop=True)
  return(df_train, df_test)

# Create training and test data frames
df_train, df_test = create_training_test_set(df_filtered)

# Convert time (string) into numeric (real) variable (training set)
for i in range(len(df_train)):
  ss = df_train.Start_Time[i]
  if len(ss)>20:
    ss = ss[0:19]
  time = datetime.strptime(ss,'%Y-%m-%d %H:%M:%S')
  df_train.loc[i,'Start_Time'] = time.hour + time.minute/60

# Convert time (string) into numeric (real) variable (test set)
for i in range(len(df_test)):
  ss = df_test.Start_Time[i]
  if len(ss)>20:
    ss = ss[0:19]
  time = datetime.strptime(ss,'%Y-%m-%d %H:%M:%S')
  df_test.loc[i,'Start_Time'] = time.hour + time.minute/60

# Separate training set into response and explanatory variables
y_train = df_train.loc[:,['Severity']]
X_train = df_train.loc[:,['Start_Time','Start_Lat','Start_Lng','Temperature(F)','Wind_Speed(mph)','Humidity(%)','Visibility(mi)','Precipitation(in)']]

# Separate training set into response and explanatory variables
y_test = df_test.loc[:,['Severity']]
X_test = df_test.loc[:,['Start_Time','Start_Lat','Start_Lng','Temperature(F)','Wind_Speed(mph)','Humidity(%)','Visibility(mi)','Precipitation(in)']]

"""## SVM (rbf kernel)"""

# Compute rbf kernel SVM
rbf = svm.SVC(kernel='rbf', gamma=0.5, C=0.1).fit(X_train, y_train)

# Compute the prediction for the rbf kernel SVM
rbf_pred = rbf.predict(X_test)

# Compute the confussion matrix
def conf_mat(y_test,y_pred):
  m = np.zeros((4,4))

  aux = np.where(y_test == 1)[0]
  aux2 = y_pred[aux]
  m[0,:] = np.array([ len(aux2[aux2 == 1]),len(aux2[aux2 == 2]),len(aux2[aux2 == 3]),len(aux2[aux2 == 4]) ])

  aux = np.where(y_test == 2)[0]
  aux2 = y_pred[aux]
  m[1,:] = np.array([ len(aux2[aux2 == 1]),len(aux2[aux2 == 2]),len(aux2[aux2 == 3]),len(aux2[aux2 == 4]) ])

  aux = np.where(y_test == 3)[0]
  aux2 = y_pred[aux]
  m[2,:] = np.array([ len(aux2[aux2 == 1]),len(aux2[aux2 == 2]),len(aux2[aux2 == 3]),len(aux2[aux2 == 4]) ])

  aux = np.where(y_test == 4)[0]
  aux2 = y_pred[aux]
  m[3,:] = np.array([ len(aux2[aux2 == 1]),len(aux2[aux2 == 2]),len(aux2[aux2 == 3]),len(aux2[aux2 == 4]) ])

  return(m)

# Print confusion matrix
m = conf_mat(y_test.Severity.to_numpy(),rbf_pred)
print(m)

"""## Random Forest"""

# Apply random forest
rf = RandomForestRegressor(n_estimators = 100, random_state = 42)
rf.fit(X_train, y_train)

# Compute predictions
predictions = rf.predict(X_test)

# Print confusion matrix
m = conf_mat(y_test.Severity.to_numpy(),np.round(predictions))
print(m)
